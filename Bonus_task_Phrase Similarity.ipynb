{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase Similarity \n",
    "\n",
    "### Zero short setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "0.5\n",
      "0.6\n",
      "0.85\n",
      "                                    Phrase Pair  Similarity Score\n",
      "0  newly formed camp - recently made encampment              0.80\n",
      "1             one data - a particular statistic              0.50\n",
      "2       particular structure - specific edifice              0.60\n",
      "3   involved people - participating individuals              0.85\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "\n",
    "phrases = [\n",
    "    (\"newly formed camp\", \"recently made encampment\"),\n",
    "    (\"one data\", \"a particular statistic\"),\n",
    "    (\"particular structure\", \"specific edifice\"),\n",
    "    (\"involved people\", \"participating individuals\")\n",
    "]\n",
    "def compute_phrase_similarity(phrases):\n",
    "    similarity_scores = []\n",
    "    for phrase1, phrase2 in phrases:\n",
    "        \n",
    "        prompt = f\"Phrase 1: {phrase1}\\nPhrase 2: {phrase2}\\nHow similar are these phrases on a scale from 0 to 1? Provide a numerical similarity score. Your output should only give similarity score in float.\"\n",
    "        \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI language model.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        similarity_score = response.choices[0].message[\"content\"].strip()\n",
    "        print(similarity_score)\n",
    "        try:\n",
    "            similarity_score = float(similarity_score)\n",
    "        except ValueError:\n",
    "            similarity_score = 0.0  \n",
    "        similarity_scores.append(similarity_score)\n",
    "    return similarity_scores\n",
    "\n",
    "\n",
    "similarity_scores = compute_phrase_similarity(phrases)\n",
    "\n",
    "results_df = pd.DataFrame({\"Phrase Pair\": [f\"{phrase[0]} - {phrase[1]}\" for phrase in phrases],\n",
    "                           \"Similarity Score\": similarity_scores})\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Phrase Pair  Similarity Score\n",
      "0  newly formed camp - recently made encampment              0.75\n",
      "1             one data - a particular statistic              0.40\n",
      "2       particular structure - specific edifice              0.85\n",
      "3   involved people - participating individuals              0.90\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "phrases = [\n",
    "    (\"newly formed camp\", \"recently made encampment\"),\n",
    "    (\"one data\", \"a particular statistic\"),\n",
    "    (\"particular structure\", \"specific edifice\"),\n",
    "    (\"involved people\", \"participating individuals\")\n",
    "]\n",
    "\n",
    "def compute_phrase_similarity(phrases):   # Function to compute similarity scores for phrases\n",
    "    similarity_scores = []\n",
    "    for phrase1, phrase2 in phrases:\n",
    "        prompt = f\"How similar are the phrases '{phrase1}' and '{phrase2}'? Provide a similarity score between 0 and 1.\"\n",
    "        response = genai.generate_text(prompt=prompt)\n",
    "        output = response.candidates[0]['output']\n",
    "        try:\n",
    "            similarity_score = float(output.strip())\n",
    "        except ValueError:\n",
    "            similarity_score = 0.0 \n",
    "        similarity_scores.append(similarity_score)\n",
    "    return similarity_scores\n",
    "\n",
    "similarity_scores = compute_phrase_similarity(phrases)\n",
    "\n",
    "results_df = pd.DataFrame({\"Phrase Pair\": [f\"{phrase[0]} - {phrase[1]}\" for phrase in phrases],\n",
    "                           \"Similarity Score\": similarity_scores})\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`all-mpnet-base-v2` from the Sentence Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score (Phrase: 'newly formed camp' vs 'recently made encampment'): 0.7058581113815308\n",
      "Similarity Score (Phrase: 'one data' vs 'a particular statistic'): 0.3323671221733093\n",
      "Similarity Score (Phrase: 'particular structure' vs 'specific edifice'): 0.5267260670661926\n",
      "Similarity Score (Phrase: 'involved people' vs 'participating individuals'): 0.6591095924377441\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "phrases = [\n",
    "    (\"newly formed camp\", \"recently made encampment\"),\n",
    "    (\"one data\", \"a particular statistic\"),\n",
    "    (\"particular structure\", \"specific edifice\"),\n",
    "    (\"involved people\", \"participating individuals\")\n",
    "]\n",
    "\n",
    "for phrase1, phrase2 in phrases:\n",
    "  phrase1_embedding = model.encode(phrase1)\n",
    "  phrase2_embedding = model.encode(phrase2)\n",
    "  similarity = util.pytorch_cos_sim(phrase1_embedding, phrase2_embedding).item()\n",
    "  print(f\"Similarity Score (Phrase: '{phrase1}' vs '{phrase2}'): {similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Short Editing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "phrases_with_scores = [\n",
    "    ((\"newly formed camp\", \"recently made encampment\"), 0.8),\n",
    "    ((\"one data\", \"a particular statistic\"), 0.6),\n",
    "    ((\"particular structure\", \"specific edifice\"), 0.7),\n",
    "    ((\"involved people\", \"participating individuals\"), 0.9)\n",
    "]\n",
    "\n",
    "def compute_phrase_similarity(phrases_with_scores):\n",
    "    similarity_scores = []\n",
    "    for (phrase1, phrase2), true_similarity_score in phrases_with_scores:\n",
    "    \n",
    "        prompt = f\"Phrase 1: {phrase1}\\nPhrase 2: {phrase2}\\nHow similar are these phrases on a scale from 0 to 1? Provide a numerical similarity score. Your output should only give similarity score in float.\"\n",
    "        \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI language model.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        similarity_score = response.choices[0].message[\"content\"].strip()\n",
    "        try:\n",
    "            similarity_score = float(similarity_score)\n",
    "        except ValueError:\n",
    "            similarity_score = 0.0  \n",
    "        similarity_scores.append(similarity_score)\n",
    "    return similarity_scores\n",
    "\n",
    "\n",
    "similarity_scores = compute_phrase_similarity(phrases_with_scores)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame({\"Phrase Pair\": [f\"{phrase[0]} - {phrase[1]}\" for phrase, _ in phrases_with_scores],\n",
    "                           \"True Similarity Score\": [score for _, score in phrases_with_scores],\n",
    "                           \"Computed Similarity Score\": similarity_scores})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase Pair</th>\n",
       "      <th>True Similarity Score</th>\n",
       "      <th>Computed Similarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>newly formed camp - recently made encampment</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one data - a particular statistic</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>particular structure - specific edifice</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>involved people - participating individuals</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Phrase Pair  True Similarity Score  \\\n",
       "0  newly formed camp - recently made encampment                    0.8   \n",
       "1             one data - a particular statistic                    0.6   \n",
       "2       particular structure - specific edifice                    0.7   \n",
       "3   involved people - participating individuals                    0.9   \n",
       "\n",
       "   Computed Similarity Score  \n",
       "0                        0.8  \n",
       "1                        0.5  \n",
       "2                        0.6  \n",
       "3                        0.8  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "\n",
    "phrases_with_scores = [\n",
    "    ((\"newly formed camp\", \"recently made encampment\"), 0.8),\n",
    "    ((\"one data\", \"a particular statistic\"), 0.6),\n",
    "    ((\"particular structure\", \"specific edifice\"), 0.7),\n",
    "    ((\"involved people\", \"participating individuals\"), 0.9)\n",
    "]\n",
    "\n",
    "def compute_phrase_similarity(phrases_with_scores):   # Function to compute similarity scores for phrases\n",
    "    similarity_scores = []\n",
    "    for (phrase1, phrase2), true_similarity_score in phrases_with_scores:\n",
    "        prompt = f\"How similar are the phrases '{phrase1}' and '{phrase2}'? Provide a similarity score between 0 and 1.\"\n",
    "        response = genai.generate_text(prompt=prompt)\n",
    "        output = response.candidates[0]['output']\n",
    "        try:\n",
    "            similarity_score = float(output.strip())\n",
    "        except ValueError:\n",
    "            similarity_score = 0.0 \n",
    "        similarity_scores.append(similarity_score)\n",
    "    return similarity_scores\n",
    "\n",
    "\n",
    "similarity_scores = compute_phrase_similarity(phrases_with_scores)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame({\"Phrase Pair\": [f\"{phrase[0]} - {phrase[1]}\" for phrase, _ in phrases_with_scores],\n",
    "                           \"True Similarity Score\": [score for _, score in phrases_with_scores],\n",
    "                           \"Computed Similarity Score\": similarity_scores})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase Pair</th>\n",
       "      <th>True Similarity Score</th>\n",
       "      <th>Computed Similarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>newly formed camp - recently made encampment</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one data - a particular statistic</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>particular structure - specific edifice</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>involved people - participating individuals</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Phrase Pair  True Similarity Score  \\\n",
       "0  newly formed camp - recently made encampment                    0.8   \n",
       "1             one data - a particular statistic                    0.6   \n",
       "2       particular structure - specific edifice                    0.7   \n",
       "3   involved people - participating individuals                    0.9   \n",
       "\n",
       "   Computed Similarity Score  \n",
       "0                       0.90  \n",
       "1                       0.30  \n",
       "2                       0.75  \n",
       "3                       0.80  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`all-mpnet-base-v2` from the Sentence Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fiftyfive/.local/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2024-06-06 19:18:10.317715: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-06 19:18:10.319152: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-06 19:18:10.346972: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-06 19:18:10.985413: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/fiftyfive/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase Pair: 'newly formed camp' - 'recently made encampment'\n",
      "True Similarity Score: 0.8\n",
      "Computed Similarity Score: 0.7058581113815308\n",
      "\n",
      "Phrase Pair: 'one data' - 'a particular statistic'\n",
      "True Similarity Score: 0.6\n",
      "Computed Similarity Score: 0.3323671221733093\n",
      "\n",
      "Phrase Pair: 'particular structure' - 'specific edifice'\n",
      "True Similarity Score: 0.7\n",
      "Computed Similarity Score: 0.5267260670661926\n",
      "\n",
      "Phrase Pair: 'involved people' - 'participating individuals'\n",
      "True Similarity Score: 0.9\n",
      "Computed Similarity Score: 0.6591095924377441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "phrases_with_scores = [\n",
    "    ((\"newly formed camp\", \"recently made encampment\"), 0.8),\n",
    "    ((\"one data\", \"a particular statistic\"), 0.6),\n",
    "    ((\"particular structure\", \"specific edifice\"), 0.7),\n",
    "    ((\"involved people\", \"participating individuals\"), 0.9)\n",
    "]\n",
    "\n",
    "for (phrase1, phrase2), true_similarity_score in phrases_with_scores:\n",
    "    phrase1_embedding = model.encode(phrase1)\n",
    "    phrase2_embedding = model.encode(phrase2)\n",
    "    similarity = util.pytorch_cos_sim(phrase1_embedding, phrase2_embedding).item()\n",
    "    print(f\"Phrase Pair: '{phrase1}' - '{phrase2}'\")\n",
    "    print(f\"True Similarity Score: {true_similarity_score}\")\n",
    "    print(f\"Computed Similarity Score: {similarity}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
